[2023-11-13T12:34:51.863+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: miai_dag.crawl_data manual__2023-11-12T14:04:39.560211+00:00 [queued]>
[2023-11-13T12:34:51.968+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: miai_dag.crawl_data manual__2023-11-12T14:04:39.560211+00:00 [queued]>
[2023-11-13T12:34:51.969+0000] {taskinstance.py:1361} INFO - Starting attempt 2 of 3
[2023-11-13T12:34:52.090+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): crawl_data> on 2023-11-12 14:04:39.560211+00:00
[2023-11-13T12:34:52.137+0000] {standard_task_runner.py:57} INFO - Started process 58466 to run task
[2023-11-13T12:34:52.225+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'miai_dag', 'crawl_data', 'manual__2023-11-12T14:04:39.560211+00:00', '--job-id', '203', '--raw', '--subdir', 'DAGS_FOLDER/dag-lstm.py', '--cfg-path', '/tmp/tmpgzf2ca9f']
[2023-11-13T12:34:52.251+0000] {standard_task_runner.py:85} INFO - Job 203: Subtask crawl_data
[2023-11-13T12:34:52.591+0000] {task_command.py:416} INFO - Running <TaskInstance: miai_dag.crawl_data manual__2023-11-12T14:04:39.560211+00:00 [running]> on host 502cd78af35e
[2023-11-13T12:41:23.536+0000] {job.py:219} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 215, in heartbeat
    heartbeat_callback(session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/local_task_job_runner.py", line 246, in heartbeat_callback
    self.task_instance.refresh_from_db()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 866, in refresh_from_db
    ti = qry.one_or_none()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2850, in one_or_none
    return self._iter().one_or_none()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-11-13T12:43:24.066+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='nguyenthung' AIRFLOW_CTX_DAG_ID='miai_dag' AIRFLOW_CTX_TASK_ID='crawl_data' AIRFLOW_CTX_EXECUTION_DATE='2023-11-12T14:04:39.560211+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-11-12T14:04:39.560211+00:00'
[2023-11-13T12:43:24.258+0000] {logging_mixin.py:151} INFO - Current Working Directory: /opt/***
[2023-11-13T12:43:24.301+0000] {logging_mixin.py:151} INFO - User Running Process: default
[2023-11-13T12:43:24.301+0000] {logging_mixin.py:151} INFO - Environment Variables: environ({'DUMB_INIT_SETSID': '1', 'HOSTNAME': '502cd78af35e', 'PYTHON_VERSION': '3.8.18', 'LANGUAGE': 'C.UTF-8', 'AIRFLOW_USER_HOME_DIR': '/home/***', 'ADDITIONAL_RUNTIME_APT_DEPS': '', 'PWD': '/opt/***', 'AIRFLOW_VERSION': '2.7.2', 'AIRFLOW__CORE__LOAD_EXAMPLES': 'false', 'AIRFLOW__API__AUTH_BACKENDS': '***.api.auth.backend.basic_auth,***.api.auth.backend.session', 'INSTALL_MSSQL_CLIENT': 'true', 'PYTHON_SETUPTOOLS_VERSION': '57.5.0', 'GUNICORN_CMD_ARGS': '--worker-tmp-dir /dev/shm', 'LD_PRELOAD': '/usr/lib/x86_64-linux-gnu/libstdc++.so.6', 'HOME': '/home/***', 'LANG': 'C.UTF-8', 'AIRFLOW_HOME': '/opt/***', 'GPG_KEY': 'E3FF2839C048B25C084DEBE9B26995E310250568', 'AIRFLOW__DATABASE__SQL_ALCHEMY_CONN': 'postgresql+psycopg2://***:***@postgres/***', 'AIRFLOW__CORE__EXECUTOR': 'LocalExecutor', 'COMMIT_SHA': 'c8b25cb3eea2bcdf951ed7c1d7d0a1f9f04db206', 'AIRFLOW_PIP_VERSION': '23.2.1', 'AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION': 'true', 'ADDITIONAL_RUNTIME_APT_COMMAND': '', '_PIP_ADDITIONAL_REQUIREMENTS': '', 'INSTALL_POSTGRES_CLIENT': 'true', 'SHLVL': '0', 'LC_MESSAGES': 'C.UTF-8', 'RUNTIME_APT_DEPS': '', 'PYTHON_PIP_VERSION': '23.0.1', 'RUNTIME_APT_COMMAND': 'echo', 'LD_LIBRARY_PATH': '/usr/local/lib', 'LC_CTYPE': 'C.UTF-8', 'AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK': 'true', 'PYTHON_GET_PIP_SHA256': '45a2bb8bf2bb5eff16fdd00faef6f29731831c7c59bd9fc2bf1f3bed511ff1fe', 'AIRFLOW__CORE__SQL_ALCHEMY_CONN': 'postgresql+psycopg2://***:***@postgres/***', 'AIRFLOW_INSTALLATION_METHOD': '', 'LC_ALL': 'C.UTF-8', 'PYTHON_GET_PIP_URL': 'https://github.com/pypa/get-pip/raw/9af82b715db434abb94a0a6f3569f43e72157346/public/get-pip.py', 'INSTALL_MYSQL_CLIENT': 'true', 'PATH': '/root/bin:/home/***/.local/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'PYTHON_BASE_IMAGE': 'python:3.8-slim-bullseye', 'AIRFLOW_UID': '50000', 'BUILD_ID': '', 'AIRFLOW__CORE__FERNET_KEY': '', 'DEBIAN_FRONTEND': 'noninteractive', 'TF2_BEHAVIOR': '1', '_AIRFLOW_PARSING_CONTEXT_DAG_ID': 'miai_dag', '_AIRFLOW_PARSING_CONTEXT_TASK_ID': 'crawl_data', 'AIRFLOW_CTX_DAG_OWNER': 'nguyenthung', 'AIRFLOW_CTX_DAG_ID': 'miai_dag', 'AIRFLOW_CTX_TASK_ID': 'crawl_data', 'AIRFLOW_CTX_EXECUTION_DATE': '2023-11-12T14:04:39.560211+00:00', 'AIRFLOW_CTX_TRY_NUMBER': '2', 'AIRFLOW_CTX_DAG_RUN_ID': 'manual__2023-11-12T14:04:39.560211+00:00'})
[2023-11-13T12:43:24.769+0000] {logging_mixin.py:151} INFO - https://finfo-api.vndirect.com.vn/v4/stock_prices?sort=date&q=code:DIG~date:gte:2000-01-01~date:lte:2023-11-12&size=9990&page=1
[2023-11-13T12:43:33.962+0000] {local_task_job_runner.py:294} WARNING - State of this instance has been externally set to None. Terminating instance.
[2023-11-13T12:43:34.092+0000] {process_utils.py:131} INFO - Sending 15 to group 58466. PIDs of all processes in the group: [58466]
[2023-11-13T12:43:34.092+0000] {process_utils.py:86} INFO - Sending the signal 15 to group 58466
[2023-11-13T12:43:34.098+0000] {taskinstance.py:1632} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-11-13T12:43:34.334+0000] {taskinstance.py:1937} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dag-lstm.py", line 57, in craw_stock_price
    stock_price_df = pd.concat([stock_price_df, pd.DataFrame([stock])], ignore_index=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/frame.py", line 790, in __init__
    mgr = arrays_to_mgr(
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py", line 120, in arrays_to_mgr
    arrays, refs = _homogenize(arrays, index, dtype)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/internals/construction.py", line 607, in _homogenize
    val = sanitize_array(val, index, dtype=dtype, copy=False)
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/construction.py", line 544, in sanitize_array
    elif isinstance(data, ABCExtensionArray):
  File "/home/airflow/.local/lib/python3.8/site-packages/pandas/core/dtypes/generic.py", line 44, in _instancecheck
    return _check(inst) and not isinstance(inst, type)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1634, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-11-13T12:43:34.721+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=miai_dag, task_id=crawl_data, execution_date=20231112T140439, start_date=20231113T123451, end_date=20231113T124334
[2023-11-13T12:43:34.765+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 203 for task crawl_data (Task received SIGTERM signal; 58466)
[2023-11-13T12:43:34.808+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=58466, status='terminated', exitcode=1, started='12:34:51') (58466) terminated with exit code 1
